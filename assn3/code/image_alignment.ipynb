{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation of panorama algorithm with RANSAC\n",
    "20220259 전현빈"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jz/79h17zh14cqbn2c_95yq690h0000gn/T/ipykernel_66797/4191210389.py:45: RuntimeWarning: divide by zero encountered in divide\n",
      "  projected = projected[:2] / projected[2]\n",
      "/var/folders/jz/79h17zh14cqbn2c_95yq690h0000gn/T/ipykernel_66797/4191210389.py:45: RuntimeWarning: invalid value encountered in divide\n",
      "  projected = projected[:2] / projected[2]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "from typing import List, Tuple\n",
    "\n",
    "def detect_features_and_match(img1: np.ndarray, img2: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"Detect SIFT features and find matches between two images.\"\"\"\n",
    "    sift = cv2.SIFT_create()\n",
    "    kp1, des1 = sift.detectAndCompute(img1, None)\n",
    "    kp2, des2 = sift.detectAndCompute(img2, None)\n",
    "    \n",
    "    matcher = cv2.BFMatcher(cv2.NORM_L2, crossCheck=True)\n",
    "    matches = matcher.match(des1, des2)\n",
    "    \n",
    "    pts1 = np.float32([kp1[m.queryIdx].pt for m in matches]).reshape(-1, 2)\n",
    "    pts2 = np.float32([kp2[m.trainIdx].pt for m in matches]).reshape(-1, 2)\n",
    "    \n",
    "    return pts1, pts2\n",
    "\n",
    "def custom_ransac(pts1: np.ndarray, pts2: np.ndarray, num_iterations: int = 1000, \n",
    "                  threshold: float = 10.0, min_inliers: int = 4) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"Custom RANSAC to find best homography.\"\"\"\n",
    "    best_H = None\n",
    "    best_inliers = []\n",
    "    max_inliers = 0\n",
    "    \n",
    "    for _ in range(num_iterations):\n",
    "        indices = random.sample(range(len(pts1)), 4)\n",
    "        src_pts = pts1[indices]\n",
    "        dst_pts = pts2[indices]\n",
    "        \n",
    "        H, _ = cv2.findHomography(src_pts, dst_pts, method=0)\n",
    "        \n",
    "        if H is None:\n",
    "            continue\n",
    "            \n",
    "        inliers = []\n",
    "        for i in range(len(pts1)):\n",
    "            pt1 = np.array([pts1[i][0], pts1[i][1], 1])\n",
    "            pt2 = pts2[i]\n",
    "            \n",
    "            projected = H @ pt1\n",
    "            projected = projected[:2] / projected[2]\n",
    "            \n",
    "            dist = np.linalg.norm(projected - pt2)\n",
    "            if dist < threshold:\n",
    "                inliers.append(i)\n",
    "        \n",
    "        if len(inliers) > max_inliers and len(inliers) >= min_inliers:\n",
    "            max_inliers = len(inliers)\n",
    "            best_inliers = inliers\n",
    "            best_H = H\n",
    "    \n",
    "    if not best_inliers:\n",
    "        raise ValueError(\"RANSAC failed to find sufficient inliers\")\n",
    "        \n",
    "    return best_H, np.array(best_inliers)\n",
    "\n",
    "def compute_homography_with_inliers(pts1: np.ndarray, pts2: np.ndarray, \n",
    "                                  inliers: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Compute final homography using all inliers.\"\"\"\n",
    "    src_inliers = pts1[inliers]\n",
    "    dst_inliers = pts2[inliers]\n",
    "    H, _ = cv2.findHomography(src_inliers, dst_inliers, method=0)\n",
    "    return H\n",
    "\n",
    "def get_warped_image_size(images: List[np.ndarray], homographies: List[np.ndarray], \n",
    "                         ref_idx: int) -> Tuple[int, int, np.ndarray]:\n",
    "    \"\"\"Compute the size of the output panorama and the offset transform.\"\"\"\n",
    "    corners = []\n",
    "    for i, img in enumerate(images):\n",
    "        h, w = img.shape[:2]\n",
    "        img_corners = np.float32([[0, 0], [0, h], [w, h], [w, 0]]).reshape(-1, 1, 2)\n",
    "        \n",
    "        # Apply homography relative to reference image\n",
    "        if i == ref_idx:\n",
    "            transformed_corners = img_corners\n",
    "        else:\n",
    "            H = np.eye(3)\n",
    "            if i < ref_idx:\n",
    "                # Chain homographies backward\n",
    "                for j in range(i, ref_idx):\n",
    "                    H = homographies[j] @ H\n",
    "                transformed_corners = cv2.perspectiveTransform(img_corners, np.linalg.inv(H))\n",
    "            else:\n",
    "                # Chain homographies forward\n",
    "                for j in range(ref_idx, i):\n",
    "                    H = homographies[j] @ H\n",
    "                transformed_corners = cv2.perspectiveTransform(img_corners, H)\n",
    "        \n",
    "        corners.append(transformed_corners)\n",
    "    \n",
    "    corners = np.concatenate(corners, axis=0)\n",
    "    x_min, y_min = np.int32(corners.min(axis=0).ravel())\n",
    "    x_max, y_max = np.int32(corners.max(axis=0).ravel())\n",
    "    \n",
    "    width = x_max - x_min\n",
    "    height = y_max - y_min\n",
    "    offset_transform = np.array([[1, 0, -x_min], [0, 1, -y_min], [0, 0, 1]], dtype=np.float32)\n",
    "    \n",
    "    return width, height, offset_transform\n",
    "\n",
    "def alpha_blending(img1: np.ndarray, img2: np.ndarray, mask1: np.ndarray, mask2: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Perform alpha blending for seamless stitching.\"\"\"\n",
    "    mask_sum = mask1 + mask2\n",
    "    mask_sum[mask_sum == 0] = 1\n",
    "    alpha1 = mask1 / mask_sum\n",
    "    alpha2 = mask2 / mask_sum\n",
    "    \n",
    "    result = np.zeros_like(img1, dtype=np.float32)\n",
    "    for c in range(3):\n",
    "        result[:, :, c] = img1[:, :, c] * alpha1 + img2[:, :, c] * alpha2\n",
    "    \n",
    "    return result.astype(np.uint8)\n",
    "\n",
    "def stitch_images(images: List[np.ndarray], ref_idx: int = 0) -> np.ndarray:\n",
    "    \"\"\"Stitch images into a panorama with the specified reference image.\"\"\"\n",
    "    if len(images) < 2:\n",
    "        raise ValueError(\"At least two images are required\")\n",
    "    \n",
    "    if ref_idx < 0 or ref_idx >= len(images):\n",
    "        raise ValueError(\"Invalid reference index\")\n",
    "    \n",
    "    # Convert images to grayscale\n",
    "    gray_images = [cv2.cvtColor(img, cv2.COLOR_BGR2GRAY) for img in images]\n",
    "    \n",
    "    # Compute homographies between consecutive images\n",
    "    homographies = []\n",
    "    for i in range(len(images) - 1):\n",
    "        pts1, pts2 = detect_features_and_match(gray_images[i+1], gray_images[i])\n",
    "        H, inliers = custom_ransac(pts1, pts2)\n",
    "        H = compute_homography_with_inliers(pts1, pts2, inliers)\n",
    "        homographies.append(H)\n",
    "    \n",
    "    # Compute output size and offset\n",
    "    width, height, offset_transform = get_warped_image_size(images, homographies, ref_idx)\n",
    "    \n",
    "    # Initialize panorama\n",
    "    panorama = np.zeros((height, width, 3), dtype=np.uint8)\n",
    "    \n",
    "    # Warp and blend images\n",
    "    for i, img in enumerate(images):\n",
    "        if i == ref_idx:\n",
    "            # Warp reference image\n",
    "            H_total = offset_transform\n",
    "        else:\n",
    "            H = np.eye(3)\n",
    "            if i < ref_idx:\n",
    "                # Chain homographies backward\n",
    "                for j in range(i, ref_idx):\n",
    "                    H = homographies[j] @ H\n",
    "                H_total = offset_transform @ np.linalg.inv(H)\n",
    "            else:\n",
    "                # Chain homographies forward\n",
    "                for j in range(ref_idx, i):\n",
    "                    H = homographies[j] @ H\n",
    "                H_total = offset_transform @ H\n",
    "        \n",
    "        # Warp image and mask\n",
    "        warped = cv2.warpPerspective(img, H_total, (width, height))\n",
    "        mask = cv2.warpPerspective(np.ones_like(gray_images[i], dtype=np.float32), \n",
    "                                 H_total, (width, height))\n",
    "        \n",
    "        # Blend\n",
    "        if i == 0:\n",
    "            panorama = warped\n",
    "            panorama_mask = mask\n",
    "        else:\n",
    "            panorama = alpha_blending(panorama, warped, panorama_mask, mask)\n",
    "            panorama_mask = np.clip(panorama_mask + mask, 0, 1)\n",
    "    \n",
    "    return panorama\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    # 1. Specify image folder path\n",
    "    image_dir = \"/Users/jeonhyeonbin/Documents/CSED551/assn1/assn3/images\"\n",
    "    \n",
    "    # 2. Load all images using glob\n",
    "    image_paths = sorted(glob.glob(os.path.join(image_dir, \"*.*\")))\n",
    "    \n",
    "    # 3. Read images with OpenCV\n",
    "    images = [cv2.imread(p) for p in image_paths]\n",
    "    \n",
    "    # Check if images are loaded correctly\n",
    "    if not image_paths or any(img is None for img in images):\n",
    "        raise ValueError(\"Failed to load images from the specified directory\")\n",
    "    \n",
    "    # 4. Create panorama with first image as reference\n",
    "    panorama = stitch_images(images, ref_idx=0)\n",
    "    \n",
    "    # 5. Save and display result\n",
    "    cv2.imwrite(\"panorama_output.jpg\", panorama)\n",
    "    cv2.imshow(\"Panorama\", panorama)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# No Blending"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/jz/79h17zh14cqbn2c_95yq690h0000gn/T/ipykernel_66797/3259214126.py:50: RuntimeWarning: invalid value encountered in divide\n",
      "  projected = projected[:2] / projected[2]\n",
      "/var/folders/jz/79h17zh14cqbn2c_95yq690h0000gn/T/ipykernel_66797/3259214126.py:50: RuntimeWarning: divide by zero encountered in divide\n",
      "  projected = projected[:2] / projected[2]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import random\n",
    "from typing import List, Tuple\n",
    "\n",
    "def detect_features_and_match(img1: np.ndarray, img2: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"Detect SIFT features and find matches between two images.\"\"\"\n",
    "    sift = cv2.SIFT_create()\n",
    "    kp1, des1 = sift.detectAndCompute(img1, None)\n",
    "    kp2, des2 = sift.detectAndCompute(img2, None)\n",
    "    \n",
    "    matcher = cv2.BFMatcher(cv2.NORM_L2)\n",
    "    matches = matcher.knnMatch(des1, des2, k=2)\n",
    "    \n",
    "    good_matches = []\n",
    "    for m, n in matches:\n",
    "        if m.distance < 0.8 * n.distance:\n",
    "            good_matches.append(m)\n",
    "    \n",
    "    pts1 = np.float32([kp1[m.queryIdx].pt for m in good_matches]).reshape(-1, 2)\n",
    "    pts2 = np.float32([kp2[m.trainIdx].pt for m in good_matches]).reshape(-1, 2)\n",
    "    \n",
    "    return pts1, pts2\n",
    "\n",
    "def custom_ransac(pts1: np.ndarray, pts2: np.ndarray, num_iterations: int = 3000, \n",
    "                  threshold: float = 10.0, min_inliers: int = 4) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"Custom RANSAC to find best homography.\"\"\"\n",
    "    best_H = None\n",
    "    best_inliers = []\n",
    "    max_inliers = 0\n",
    "    \n",
    "    for _ in range(num_iterations):\n",
    "        indices = random.sample(range(len(pts1)), 4)\n",
    "        src_pts = pts1[indices]\n",
    "        dst_pts = pts2[indices]\n",
    "        \n",
    "        H, _ = cv2.findHomography(src_pts, dst_pts, method=0)\n",
    "        \n",
    "        if H is None:\n",
    "            continue\n",
    "            \n",
    "        inliers = []\n",
    "        for i in range(len(pts1)):\n",
    "            pt1 = np.array([pts1[i][0], pts1[i][1], 1])\n",
    "            pt2 = pts2[i]\n",
    "            \n",
    "            projected = H @ pt1\n",
    "            projected = projected[:2] / projected[2]\n",
    "            \n",
    "            dist = np.linalg.norm(projected - pt2)\n",
    "            if dist < threshold:\n",
    "                inliers.append(i)\n",
    "        \n",
    "        if len(inliers) > max_inliers and len(inliers) >= min_inliers:\n",
    "            max_inliers = len(inliers)\n",
    "            best_inliers = inliers\n",
    "            best_H = H\n",
    "    \n",
    "    if not best_inliers:\n",
    "        raise ValueError(\"RANSAC failed to find sufficient inliers\")\n",
    "        \n",
    "    return best_H, np.array(best_inliers)\n",
    "\n",
    "def compute_homography_with_inliers(pts1: np.ndarray, pts2: np.ndarray, \n",
    "                                  inliers: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Compute final homography using all inliers.\"\"\"\n",
    "    src_inliers = pts1[inliers]\n",
    "    dst_inliers = pts2[inliers]\n",
    "    H, _ = cv2.findHomography(src_inliers, dst_inliers, method=0)\n",
    "    return H\n",
    "\n",
    "def get_warped_image_size(images: List[np.ndarray], homographies: List[np.ndarray], \n",
    "                         ref_idx: int) -> Tuple[int, int, np.ndarray]:\n",
    "    \"\"\"Compute the size of the output panorama and the offset transform.\"\"\"\n",
    "    corners = []\n",
    "    for i, img in enumerate(images):\n",
    "        h, w = img.shape[:2]\n",
    "        img_corners = np.float32([[0, 0], [0, h], [w, h], [w, 0]]).reshape(-1, 1, 2)\n",
    "        \n",
    "        if i == ref_idx:\n",
    "            transformed_corners = img_corners\n",
    "        else:\n",
    "            H = np.eye(3)\n",
    "            if i < ref_idx:\n",
    "                for j in range(i, ref_idx):\n",
    "                    H = homographies[j] @ H\n",
    "                transformed_corners = cv2.perspectiveTransform(img_corners, np.linalg.inv(H))\n",
    "           \n",
    "            else:\n",
    "                for j in range(ref_idx, i):\n",
    "                    H = homographies[j] @ H\n",
    "                transformed_corners = cv2.perspectiveTransform(img_corners, H)\n",
    "        \n",
    "        corners.append(transformed_corners)\n",
    "    \n",
    "    corners = np.concatenate(corners, axis=0)\n",
    "    x_min, y_min = np.int32(corners.min(axis=0).ravel())\n",
    "    x_max, y_max = np.int32(corners.max(axis=0).ravel())\n",
    "    \n",
    "    width = x_max - x_min\n",
    "    height = y_max - y_min\n",
    "    offset_transform = np.array([[1, 0, -x_min], [0, 1, -y_min], [0, 0, 1]], dtype=np.float32)\n",
    "    \n",
    "    return width, height, offset_transform\n",
    "\n",
    "def color_correction(img: np.ndarray, ref_img: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Adjust image color in LAB space to match reference image.\"\"\"\n",
    "    img_lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
    "    ref_lab = cv2.cvtColor(ref_img, cv2.COLOR_BGR2LAB)\n",
    "    corrected_lab = img_lab.copy()\n",
    "    for c in range(3):\n",
    "        img_mean = np.mean(img_lab[:, :, c])\n",
    "        ref_mean = np.mean(ref_lab[:, :, c])\n",
    "        if img_mean != 0:\n",
    "            corrected_lab[:, :, c] = np.clip(img_lab[:, :, c] * (ref_mean / img_mean), 0, 255)\n",
    "    return cv2.cvtColor(corrected_lab, cv2.COLOR_LAB2BGR)\n",
    "\n",
    "def simple_composite(img1: np.ndarray, img2: np.ndarray, mask1: np.ndarray, mask2: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Combine images without blending, using masks to overwrite.\"\"\"\n",
    "    # Create binary masks\n",
    "    mask1_bin = (mask1 > 0).astype(np.uint8)\n",
    "    mask2_bin = (mask2 > 0).astype(np.uint8)\n",
    "    \n",
    "    # Prioritize img2 in overlapping regions\n",
    "    result = img1.copy()\n",
    "    overlap_mask = mask2_bin.astype(bool)\n",
    "    result[overlap_mask] = img2[overlap_mask]\n",
    "    \n",
    "    return result\n",
    "\n",
    "def stitch_images(images: List[np.ndarray], ref_idx: int = 0) -> np.ndarray:\n",
    "    \"\"\"Stitch images into a panorama without blending.\"\"\"\n",
    "    if len(images) < 2:\n",
    "        raise ValueError(\"At least two images are required\")\n",
    "    \n",
    "    if len(images) == 2:\n",
    "        gray_images = [cv2.equalizeHist(cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)) for img in images]\n",
    "        pts1, pts2 = detect_features_and_match(gray_images[1], gray_images[0])\n",
    "        H, inliers = custom_ransac(pts1, pts2, num_iterations=3000, threshold=10.0, min_inliers=4)\n",
    "        H = compute_homography_with_inliers(pts1, pts2, inliers)\n",
    "        \n",
    "        width, height, offset_transform = get_warped_image_size(images, [H], ref_idx)\n",
    "        panorama = np.zeros((height, width, 3), dtype=np.uint8)\n",
    "        \n",
    "        for i, img in enumerate(images):\n",
    "            if i != ref_idx:\n",
    "                img = color_correction(img, images[ref_idx])\n",
    "            \n",
    "            H_total = offset_transform if i == ref_idx else offset_transform @ H\n",
    "            warped = cv2.warpPerspective(img, H_total, (width, height))\n",
    "            mask = cv2.warpPerspective(np.ones_like(gray_images[i], dtype=np.float32), \n",
    "                                     H_total, (width, height))\n",
    "            # No Gaussian blur to emphasize seam\n",
    "            if i == 0:\n",
    "                panorama = warped\n",
    "                panorama_mask = mask\n",
    "            else:\n",
    "                panorama = simple_composite(panorama, warped, panorama_mask, mask)\n",
    "                panorama_mask = np.clip(panorama_mask + mask, 0, 1)\n",
    "        return panorama\n",
    "    \n",
    "    first_pair = stitch_images(images[:2], ref_idx=0)\n",
    "    remaining = [first_pair] + images[2:]\n",
    "    return stitch_images(remaining, ref_idx=0)\n",
    "\n",
    "# Main execution\n",
    "if __name__ == \"__main__\":\n",
    "    image_dir = \"/Users/jeonhyeonbin/Documents/CSED551/assn1/assn3/images\"\n",
    "    image_paths = sorted(glob.glob(os.path.join(image_dir, \"*.*\")))\n",
    "    images = [cv2.imread(p) for p in image_paths]\n",
    "    \n",
    "    if not image_paths or any(img is None for img in images):\n",
    "        raise ValueError(\"Failed to load images from the specified directory\")\n",
    "    \n",
    "    panorama = stitch_images(images, ref_idx=0)\n",
    "    \n",
    "    cv2.imwrite(\"panorama_no_blending.jpg\", panorama)\n",
    "    cv2.imshow(\"Panorama (No Blending)\", panorama)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
