{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import glob\n",
    "import argparse\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def detect_and_match_features(img1, img2):\n",
    "    # SIFT keypoints + descriptors\n",
    "    sift = cv2.SIFT_create()\n",
    "    kp1, des1 = sift.detectAndCompute(img1, None)\n",
    "    kp2, des2 = sift.detectAndCompute(img2, None)\n",
    "    # BFMatcher with L2 norm\n",
    "    bf = cv2.BFMatcher(cv2.NORM_L2, crossCheck=True)\n",
    "    matches = sorted(bf.match(des1, des2), key=lambda x: x.distance)\n",
    "    pts1 = np.float32([kp1[m.queryIdx].pt for m in matches])\n",
    "    pts2 = np.float32([kp2[m.trainIdx].pt for m in matches])\n",
    "    return pts1, pts2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ransac_homography(src_pts, dst_pts, thresh=5.0, max_iter=2000):\n",
    "    best_H, best_inliers = None, []\n",
    "    n = len(src_pts)\n",
    "    if n < 4:\n",
    "        return None\n",
    "    for _ in range(max_iter):\n",
    "        idx = np.random.choice(n, 4, replace=False)\n",
    "        H = cv2.getPerspectiveTransform(src_pts[idx], dst_pts[idx])\n",
    "        proj = cv2.perspectiveTransform(src_pts.reshape(-1,1,2), H).reshape(-1,2)\n",
    "        d = np.linalg.norm(dst_pts - proj, axis=1)\n",
    "        inliers = np.where(d < thresh)[0]\n",
    "        if len(inliers) > len(best_inliers):\n",
    "            best_inliers = inliers\n",
    "            best_H = H\n",
    "    if best_H is not None and len(best_inliers) >= 4:\n",
    "        best_H, _ = cv2.findHomography(src_pts[best_inliers], dst_pts[best_inliers], 0)\n",
    "    return best_H\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accumulate_homographies(images, ref_idx=0):\n",
    "    N = len(images)\n",
    "    Hs = [None]*N\n",
    "    Hs[ref_idx] = np.eye(3, dtype=np.float32)\n",
    "    # backward\n",
    "    for i in range(ref_idx-1, -1, -1):\n",
    "        p_src, p_dst = detect_and_match_features(images[i], images[i+1])\n",
    "        H = ransac_homography(p_src, p_dst)\n",
    "        Hs[i] = Hs[i+1] @ np.linalg.inv(H)\n",
    "    # forward\n",
    "    for i in range(ref_idx+1, N):\n",
    "        p_src, p_dst = detect_and_match_features(images[i], images[i-1])\n",
    "        H = ransac_homography(p_src, p_dst)\n",
    "        Hs[i] = Hs[i-1] @ H\n",
    "    return Hs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def warp_images(images, Hs):\n",
    "    # Compute canvas bounds\n",
    "    corners = []\n",
    "    for img, H in zip(images, Hs):\n",
    "        h, w = img.shape[:2]\n",
    "        pts = np.array([[0,0],[w,0],[w,h],[0,h]], np.float32).reshape(-1,1,2)\n",
    "        warped = cv2.perspectiveTransform(pts, H)\n",
    "        corners.append(warped.reshape(-1,2))\n",
    "    all_pts = np.vstack(corners)\n",
    "    x_min, y_min = np.int32(all_pts.min(axis=0) - 0.5)\n",
    "    x_max, y_max = np.int32(all_pts.max(axis=0) + 0.5)\n",
    "    trans = np.array([[1,0,-x_min],[0,1,-y_min],[0,0,1]], np.float32)\n",
    "    canvas = (x_max-x_min, y_max-y_min)\n",
    "\n",
    "    warped_imgs, masks = [], []\n",
    "    for img, H in zip(images, Hs):\n",
    "        Ht = trans @ H\n",
    "        wimg = cv2.warpPerspective(img, Ht, canvas)\n",
    "        mask = cv2.warpPerspective(np.ones(img.shape[:2], np.uint8), Ht, canvas)\n",
    "        warped_imgs.append(wimg)\n",
    "        masks.append(mask)\n",
    "    return warped_imgs, masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def blend_images_poisson(warped_imgs, masks, ref_idx=0):\n",
    "    # 시작 파노라마는 기준 이미지의 워핑 결과\n",
    "    panorama = warped_imgs[ref_idx].copy()\n",
    "    N = len(warped_imgs)\n",
    "    for i in range(N):\n",
    "        if i == ref_idx:\n",
    "            continue\n",
    "        mask = masks[i]\n",
    "        if mask.sum() == 0:\n",
    "            continue\n",
    "        # 마스크 영역 ROI 계산\n",
    "        x,y,w,h = cv2.boundingRect(mask)\n",
    "        src_roi  = warped_imgs[i][y:y+h, x:x+w]\n",
    "        mask_roi = mask[y:y+h, x:x+w]\n",
    "        # 중심점\n",
    "        center = (x + w//2, y + h//2)\n",
    "        # Poisson 블렌딩\n",
    "        panorama = cv2.seamlessClone(src_roi, panorama, mask_roi, center, cv2.NORMAL_CLONE)\n",
    "    return panorama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stitch_images(images, ref_idx=0):\n",
    "    Hs = accumulate_homographies(images, ref_idx)\n",
    "    warped, masks = warp_images(images, Hs)\n",
    "    pano = blend_images_poisson(warped, masks, ref_idx)\n",
    "    return pano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--images_dir\",  required=True, help=\"Input images folder\")\n",
    "    parser.add_argument(\"--output\",      default=\"panorama.jpg\", help=\"Output filename\")\n",
    "    parser.add_argument(\"--ref_idx\", type=int, default=0, help=\"Reference image index\")\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    paths = sorted(glob.glob(os.path.join(args.images_dir, \"*.*\")))\n",
    "    imgs  = [cv2.imread(p) for p in paths]\n",
    "    if any(im is None for im in imgs):\n",
    "        raise RuntimeError(\"이미지를 불러오는 데 실패했습니다.\")\n",
    "    \n",
    "    result = stitch_images(imgs, args.ref_idx)\n",
    "    cv2.imwrite(args.output, result)\n",
    "    print(f\"파노라마가 {args.output}에 저장되었습니다.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
